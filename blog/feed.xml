<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
 
 <title>Blogging with Hindsight</title>
 <link href="http://hindsighttesting.com/blog/feed.xml" rel="self"/>
 <link href="http://hindsighttesting.com/"/>
 <updated>2013-08-14T14:09:17+01:00</updated>
 <id>http://hindsighttesting.com/blog</id>
 <author>
   <name>Hindsight Software Ltd</name>
   <email>mail@hindsighttesting.com</email>
 </author>

 
 <entry>
   <title>Cross browser testing JavaScript</title>
   <link href="http://hindsighttesting.com/blog/2013/08/14/Cross-browser-testing-JavaScript/"/>
   <updated>2013-08-14T00:00:00+01:00</updated>
   <id>http://recursive-design.com/blog/2013/08/14/Cross-browser-testing-JavaScript</id>
   <content type="xhtml">&lt;p&gt;One mistake many people make is running their selenium test suites with every browser combination... you don't need to! Rendering problems are probably the biggest cross browser compatibility issue, and you can't actually test for these with Functional Tests. So by running Selenium tests across many browsers you are really testing JavaScript and DOM compatibility.&lt;/p&gt;

&lt;p&gt;Running our Selenium tests across many browsers was our JavaScript compatibility strategy, but it proved inefficient as we ended up with bugs in Internet Explorer; how embarrassing!&lt;/p&gt;

&lt;p&gt;We were sure we had a good Selenium test suite so how did miss the bugs? We decided to investigate. We started to look at code coverage of JavaScript in our test suite and found that only 72% of JavaScript was executed. That leaves 18% untested for compatibility and our IE bugs were located in this area. We spent some time coming up with possible solutions to our poor compatibly testing and found a simple solution.&lt;/p&gt;

&lt;p&gt;We've been using TDD (Test Driven Development) with JavaScript but our use wasn't consistent. We decided the front end code should have the same techniques and rigour applied as the back end code, so we wanted to improve on it.&lt;/p&gt;

&lt;p&gt;By reusing and running these TDD unit tests across all the different browser combinations required for compatibility, you can guarantee good compatibility of JavaScript and DOM. This is due to the fact many complex error situations can be simulated in unit tests compared to functional tests. If developers, when developing JavaScript are forcing themselves to do TDD they're creating an artifacts. As testers, we're reusing these artifacts to help us and save time and effort.&lt;/p&gt;

&lt;p&gt;Another important reason to use JavaScript unit tests is that Selenium tests are extremely slow. If we want to test across multiple browsers it can take an age as the tests are repeatability executed. Our average Selenium test time is 8 seconds per Selenium Test, and the whole suite takes 5 minutes, which could be considered a good time. But, when you compare this performance to JavaScript unit tests there is a bit of a reality check. The our average JavaScript unit tests takes 0.1 seconds and the whole suite 11 seconds.&lt;/p&gt;

&lt;h2&gt;How do we run our JavaScript tests in multiple browsers?&lt;/h2&gt;

&lt;p&gt;JsTestDriver has been used by many people for executing their tests in browsers but it has a few short comings and wasn't reliable when setup for Continuous Integration. Lucky for us we discovered Karma (formally known as Testacular) an awesome test runner for JavaScript that use real browsers to run the tests.&lt;/p&gt;

&lt;p&gt;Feature Summary:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Can launch real browsers as required&lt;/li&gt;
&lt;li&gt;Testing framework agnostic - we use Jasmine but you can use QUnit, Mocha or another framework&lt;/li&gt;
&lt;li&gt;Good support for Continuous Integration&lt;/li&gt;
&lt;li&gt;Supports code coverage with Instanbul&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Out of the box Karma provides launchers for Chrome, Chrome Canary, Safari, Firefox, Opera, PhantomJS, and IE. The problem with theses launchers is you are required to install each browser or set-up VM's with the browsers available. This is a particular problem for management of CI and teat infrastructure. Our solution to the original problem for our Selenium Tests was to set-up a Selenium Grid.&lt;/p&gt;

&lt;p&gt;As management of web browser installations was going to become a issue again for our CI cluster, we created &quot;karma-webdriver-launcher&quot;. This allows Karma to access our to for using Remote WebDriver instances for providing web browsers to Karma. This allows us to leverage our existing Selenium Grid test infrastructure with our JavaScript testing strategy.&lt;/p&gt;

&lt;h2&gt;Using Karma&lt;/h2&gt;

&lt;p&gt;Karma is written in Node.JS so you will need both Node.JS and Node Package Manager (NPM) to be installed first.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;npm install -g karma&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Install the launcher plugin for Remote WebDriver instances&lt;/p&gt;

&lt;p&gt;&lt;code&gt;npm install -g karma-webdriver-launcher&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;In the project you would like to use Karma you will need to create a karma config file. You can generate a basic Karma config file using a simple command&lt;/p&gt;

&lt;p&gt;&lt;code&gt;karma init&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;The generated config file won't have configured browsers from the WebDriver Launcher, so we have edit the config file. The 'browsers' array controls which browsers the tests should be executed within, in this case Internet Explorer.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;module.exports = function(karma) {

  karma.set({

    // base path, that will be used to resolve files and exclude
    basePath: '',


    // frameworks to use
    frameworks: ['jasmine'],


    // list of files / patterns to load in the browser
    files: [
      'Demo.js',
      'DemoSpec.js'
    ],

    // test results reporter to use
    reporters: ['progress', 'junit'],

    // Start these browsers
    browsers: ['IE'],

    ...

  });
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Add a array 'customLaunchers' to the config file, this is where we can define new Wbe Browsers Karma doesn't know about. We need to define all the browsers we want to make avaialble from our Selenium Grid within 'customLaunchers'. The first part is to define the name for the new browser so we can reference them within the 'browsers' array and then you need to specify attributes to describe the browser to launch. A full list of attributes is in the table below.&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt; Attribute   &lt;/th&gt;
&lt;th style=&quot;text-align:center;&quot;&gt; Required &lt;/th&gt;
&lt;th&gt; Notes                                          &lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt; base        &lt;/td&gt;
&lt;td style=&quot;text-align:center;&quot;&gt; true     &lt;/td&gt;
&lt;td&gt; The plugin to launch this browser; WebDriver   &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt; browserName &lt;/td&gt;
&lt;td style=&quot;text-align:center;&quot;&gt; true     &lt;/td&gt;
&lt;td&gt; The name of the browser you require, should be one of {android|chrome|firefox|htmlunit|internet explorer|iPhone|iPad|opera|safari}  &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt; config      &lt;/td&gt;
&lt;td style=&quot;text-align:center;&quot;&gt; false    &lt;/td&gt;
&lt;td&gt; The location of the remote WebDriver or Selenium Grid 2 instance. Default value of 127.0.0.1 on port 4444 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt; platform    &lt;/td&gt;
&lt;td style=&quot;text-align:center;&quot;&gt; false    &lt;/td&gt;
&lt;td&gt;    Operating System &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt; version     &lt;/td&gt;
&lt;td style=&quot;text-align:center;&quot;&gt; false    &lt;/td&gt;
&lt;td&gt;    Browser version &lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


&lt;p&gt;Example configuration for an Internet Explorer 7 instance on Windows XP.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;karma.set({

    customLaunchers: {
      'IE7-XP': {
          base: 'WebDriver',
          browserName: 'internet explorer',
          platform: 'Windows XP',
          version: '7'
      }
    },

    ...

    browsers: ['IE7-XP'],

    ...

  });
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;By default the WebDriver launcher looks the remote WebDriver or Selenium Grid 2 instance on port 4444 on the localhost. This might be suitable and when defining many browsers you don't want to have to repeat the configuration. As the Karma config is JavaScript based, just create a common object for the configuration and pass it to the 'config' attribute of each custom launcher.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var grid = {
    hostname: '127.0.0.1',
    port: 4444
  };

karma.set({

    customLaunchers: {
      'IE7-XP': {
          base: 'WebDriver',
          config: grid,
          browserName: 'internet explorer',
          platform: 'Windows XP',
          version: '7'
      }
    },

    ...

    browsers: ['IE7-XP'],

    ...

  });
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If you were to add the above example to a Karma config file and have a working Selenium Grid 2 setup you should be ready to start cross browsers testing your JavaScript. A full example project is available on &lt;a href=&quot;https://github.com/hindsightsoftware/karma-webdriver-example&quot;&gt;GitHub&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Continuous Delivery and Bamboo 5</title>
   <link href="http://hindsighttesting.com/blog/2013/07/15/continuous-delivery-bamboo-5/"/>
   <updated>2013-07-15T00:00:00+01:00</updated>
   <id>http://recursive-design.com/blog/2013/07/15/continuous-delivery-bamboo-5</id>
   <content type="xhtml">&lt;p&gt;Delivering software quickly and frequently can be a business advantage. Bamboo is known as a continuous integration tool but now has some very useful features to help with continuous delivery and can help deliver this business advantage.&lt;/p&gt;

&lt;p&gt;The idea of lean start ups is to rapidly make incremental product changes and evaluate the customer response. To do this for our product Behave for JIRA we used the concept of continuous delivery, releasing a new version every 2-3 weeks featuring new functionality based on customer feedback. This helped to establish a feature set that our customers wanted, allowing us within 6 months to go from a prototype minimum viable product to a full product that customers were paying for.&lt;/p&gt;

&lt;p&gt;So what is the problem that continuous integration solves? Well, how many times have you said as a developer &quot;it worked on my machine&quot; when you've received a bug report? Continuous integration solves this problem. It takes every single commit, builds it, packages it, and runs automated test suites (unit tests, integration tests, and selenium tests).&lt;/p&gt;

&lt;p&gt;Continuous Delivery takes continuous integration several steps further. The concept is all about patterns and building a pipeline from requirements to actually delivering working software to customer.&lt;/p&gt;

&lt;p&gt;We think creating software is just like running a marathon; the hardest part is the last few miles - getting the software into the customers hands. This is the last stage in the Continuous Delivery pipeline.&lt;/p&gt;

&lt;p&gt;Deployment projects in Bamboo 5 can help solve this. In the instance of continuous integration, you have green for good, red for bad builds etc. In continuous delivery we need to think about the release process. Taking each individual build, mapping it to a version number and releasing it. How you map it is up to you, but CI is not designed for assigning release numbers. Bamboo 5 focuses on helping to solve this final mile of delivering the software. It introduces the concept of &quot;Deployment Projects&quot;. The sole purpose of these projects are to deploy a &quot;Release&quot; of your software to a particular environment.&lt;/p&gt;

&lt;p&gt;&lt;img width=&quot;760px&quot; src=&quot;/gallery/deploymentProjectEnviroments.png&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&quot;Environments&quot; represent a logically named location where the software can be deployed. This would be an instance of a application container, platform, server or artifact repository. Common examples would be QA server, Staging and Production. Each environment is also responsible for understanding how to deploy your release artifacts to the required system or location. This deployment process is implemented using the familiar Bamboo tasks.&lt;/p&gt;

&lt;p&gt;Bamboo 5 has some awesome features for helping you solve the last mile problem of getting your software into your customers hands in a way that is quick, reliable and consistent. Bamboo 5 has been released today and you can &lt;a href=&quot;http://www.atlassian.com/software/bamboo/download&quot;&gt;download&lt;/a&gt; a copy from the Atlassian website.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Storyflow for Stash wins "Best Stash add-on" at Atlassian Codegeist 2013</title>
   <link href="http://hindsighttesting.com/blog/2013/06/30/best-stash-addon-codegeist/"/>
   <updated>2013-06-30T00:00:00+01:00</updated>
   <id>http://recursive-design.com/blog/2013/06/30/best-stash-addon-codegeist</id>
   <content type="xhtml">&lt;p&gt;&lt;img style=&quot;float:left; padding-right: 1em;&quot; src=&quot;/gallery/codegeist2013.png&quot;/&gt;&lt;/p&gt;

&lt;p&gt;Atlassian's annual Codegeist competition returned for the seventh time this year. After having won the prize for the &lt;a href=&quot;https://blogs.atlassian.com/2012/07/announcing-the-codegeist-2012-winners/&quot;&gt;best marketplace paid add-on in 2012&lt;/a&gt; with Behave for JIRA, we were excited to get involved again this year and came in on a saturday for a ShipIt day over beer and pizza.&lt;/p&gt;

&lt;p&gt;A ShipIt day is an idea that we borrowed from Atlassian, it is a 24 hour hackathon during which developers have the opportunity to make tools and products which are useful but not business essential. We decided to develop something that we were originally going to keep to ourselves; to scratch our own itch, but thought what better time to band together and develop this add-on than on a ShipIt day. In our development process we use feature branches; creating a branch for each JIRA issue. Our itch was that sometimes we forgot to update the status on the issue, therefore causing confusion at times about what had been completed and what was integrated in the next release. We came up with the idea of creating something that will automatically transition these issues when we merge our feature branches.&lt;/p&gt;

&lt;p&gt;&lt;img style=&quot;float:right; padding-left: 1em;&quot; src=&quot;/gallery/storyflow.png&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://localhost:4000/blog/2013/06/30/best-stash-addon-codegeist/&quot;&gt;Storyflow for Stash&lt;/a&gt; automatically transitions JIRA issues when pull requests are opened, declined or merged. The add-on extends the Stash-JIRA integration further by automatically creating remote issue links to pull requests in JIRA issues when the issue is referenced in the pull request. Finally, issue watchers can be mapped to Stash users and Storyflow will automatically designate them as pull request reviewers.&lt;/p&gt;

&lt;p&gt;After 24 hours of intense programming, Storyflow for Stash was ready to be unveiled and we are thrilled to announce that it won the prize for &quot;Best Stash add-on&quot;. Along with treating ourselves to a celebratory ice cream, we won some money, which we will be using to treat the team and attend the Atlassian summit in San Francisco in October.&lt;/p&gt;

&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;//www.youtube.com/embed/4J2a2_ewfJU&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;


&lt;p&gt;Get your full roundup of the Codegiest 2013 results at the &lt;a href=&quot;http://blogs.atlassian.com/2013/06/codegeist-2013-winners/&quot;&gt;Atlassian website&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Digesting CukeUp! 2013</title>
   <link href="http://hindsighttesting.com/blog/2013/04/13/cukeup-2013-digest/"/>
   <updated>2013-04-13T00:00:00+01:00</updated>
   <id>http://recursive-design.com/blog/2013/04/13/cukeup-2013-digest</id>
   <content type="xhtml">&lt;p&gt;On the 4th of April the annual &lt;a href=&quot;http://skillsmatter.com/event/java-jee/cukeup-2013&quot;&gt;CukeUp! Conference&lt;/a&gt; for Cucumber and related tools. &lt;a href=&quot;http://www.guardian.co.uk/profile/gideon-goldberg&quot;&gt;Gideon Goldberg&lt;/a&gt; from the software
testing team at The Guardian newspaper has &lt;a href=&quot;http://www.guardian.co.uk/info/developer-blog/2013/apr/10/cukeup-2013-conference-digest-gherkin-bdd&quot;&gt;written a digest&lt;/a&gt; of the
conference written sin the Gherkin format of Cucumber. Gideon has managed to successfully distil my own talk from CukeUp! in to its simplest form.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;gherkin&quot;&gt;&lt;span class=&quot;nt&quot;&gt;@alan_parkinson&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;Scenario:&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt; Creating data with the Test Data Builder pattern&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;    Given &lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;your tests require test data to be populated &lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;      as a prerequisite&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;Then &lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;you should create this data using the Test Data &lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;      Builder Pattern&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;And &lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;this data should be created through APIs&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;But &lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;not through SQL or UI manipulation&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;If this simple summary of my talk has caught your interest you can watch the real thing on the &lt;a href=&quot;http://skillsmatter.com/podcast/java-jee/creating-data-with-the-test-data-builder-pattern&quot;&gt;Skills Matter&lt;/a&gt; website&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Concurrent test execution Part 2 - Moving on from batched based concurrency to Multithreading</title>
   <link href="http://hindsighttesting.com/blog/2013/03/30/running-tests-concurrently-part2/"/>
   <updated>2013-03-30T00:00:00+00:00</updated>
   <id>http://recursive-design.com/blog/2013/03/30/running-tests-concurrently-part2</id>
   <content type="xhtml">&lt;p&gt;&lt;img src=&quot;/gallery/batched-test-jobs-feedback-timegraph1.png&quot; style=&quot;float: left; padding: 1em;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;Whilst the divide and conquer strategy of grouping tests into batches for concurrent execution is a simple method of speeding up test suites, it's not perfect. The better solution would be to execute tests concurrently using multiple threads and take advantage of the multiple core's available in modern processors.&lt;/p&gt;

&lt;p&gt;In &lt;a href=&quot;/blog/2012/10/30/running-tests-in-parallel/&quot;&gt;part 1&lt;/a&gt; of this series on concurrent test execution I went into detail on how to break test suites into batches and run each batch on separate machines. This is easy to achieve using spare hardware, Virtual Machines or Cloud computing resources. This happens to be the simplest technique for concurrent test execution as it doesn't require any additional code, but being simple is not always best.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/gallery/batched-test-jobs-feedback-timegraph2.png&quot; style=&quot;float: right; padding: 1em;&quot;/&gt;&lt;/p&gt;

&lt;h2&gt;Batch size&lt;/h2&gt;

&lt;p&gt;Selecting tests for each batch is a manual process and estimates on execution time have to be made if each batch is to be of an even size.  The number of tests in the batch group, individual execution time, and the variation in performance of the underlying hardware will all affect the total execution time of each test batch. If all test batches were triggered at the same time, you would have to wait until the longest running test batch finishes before receiving for your results.&lt;/p&gt;

&lt;div class=&quot;clear&quot;&gt;&lt;/div&gt;


&lt;h2&gt;CI Scheduling&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/gallery/batched-test-jobs-feedback-timegraph3.png&quot; style=&quot;float: left; padding: 1em;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;To avoid additional coding, each batch group is executed in it's own CI job to leverage the scheduling and resource capabilities of CI systems.
This can represent another delay to receiving test results as the jobs are bound to the available resources (Build Slaves/Agents) and scheduling
 rules of the CI server. In most CI systems you would have more than one project and many committers triggering jobs. This means your test batches
 might have to wait before they are scheduled to run, and they won't all start at the same time.&lt;/p&gt;

&lt;p&gt;Tip: Don't create more test batches than the number of available build slaves or agents. On CI systems with high resource contention (long wait
before jobs are scheduled to run) it's wise to have fewer test batches than build slaves to avoid likely contention.&lt;/p&gt;

&lt;div class=&quot;clear&quot;&gt;&lt;/div&gt;


&lt;h2&gt;How about going multi-threaded?&lt;/h2&gt;

&lt;p&gt;You are probably aware that over the last 3 years the majority of unit test runners have added the option for executing tests in parallel using threading.
 This feature is a great way to take advantage of the multiple cores available in modern processors for true concurrent test execution. If you are
 investing in your test suite for the long term I highly recommend going for true parallel test execution using threading over the batched test method.&lt;/p&gt;

&lt;h3&gt;Configuring Maven and JUnit for parallel test execution&lt;/h3&gt;

&lt;p&gt;Parallel Test execution with Maven and JUnit requires a JUnit version 4.7 or greater. Those of you already familiar with the Maven Surefire plugin may
know it can dynamically detect your JUnit version and enable and disable features based on the JUnit version. In theory by including the JUnit 4.7+
dependency in your Maven project the parallel test configuration options should be enabled, however if another dependency in your project includes an older
version of JUnit it may use this version. Luckily it's rather simple to tell Surefire which JUnit version to support by specifying a dependency of the
Surefire plugin. For JUnit 4.7+ you need to use &quot;surefire-junit47&quot;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;plugins&amp;gt;
    ...
    &amp;lt;plugin&amp;gt;
        &amp;lt;groupId&amp;gt;org.apache.maven.plugins&amp;lt;/groupId&amp;gt;
        &amp;lt;artifactId&amp;gt;maven-surefire-plugin&amp;lt;/artifactId&amp;gt;
        &amp;lt;version&amp;gt;2.14&amp;lt;/version&amp;gt;
        &amp;lt;dependencies&amp;gt;
            &amp;lt;dependency&amp;gt;
                &amp;lt;groupId&amp;gt;org.apache.maven.surefire&amp;lt;/groupId&amp;gt;
                &amp;lt;artifactId&amp;gt;surefire-junit47&amp;lt;/artifactId&amp;gt;
                &amp;lt;version&amp;gt;2.14&amp;lt;/version&amp;gt;
                &amp;lt;/dependency&amp;gt;
        &amp;lt;/dependencies&amp;gt;
    &amp;lt;/plugin&amp;gt;
    ...
&amp;lt;/plugins&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;Enabling parallel execution&lt;/h3&gt;

&lt;p&gt;Once the correct version of JUnit has been configured it's a simple case of adding the &quot;parallel&quot; parameter to the Surfire plugin configuration
 and we have a basic parallel execution configuration. The &quot;parallel&quot; parameter can have one of three values; &quot;methods&quot;, &quot;classes&quot;, or &quot;both&quot;.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;plugins&amp;gt;
    ...
    &amp;lt;plugin&amp;gt;
        &amp;lt;groupId&amp;gt;org.apache.maven.plugins&amp;lt;/groupId&amp;gt;
        &amp;lt;artifactId&amp;gt;maven-surefire-plugin&amp;lt;/artifactId&amp;gt;
        &amp;lt;version&amp;gt;2.14&amp;lt;/version&amp;gt;
        ...
        &amp;lt;configuration&amp;gt;
            &amp;lt;parallel&amp;gt;methods&amp;lt;/parallel&amp;gt;
        &amp;lt;/configuration&amp;gt;
    &amp;lt;/plugin&amp;gt;
    ...
&amp;lt;/plugins&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;By default Surefire will create a test execution thread for each available core on the machine executing the tests. This default is satisfactory
in many situations and can be overridden by the &quot;perCoreThreadCount&quot; and &quot;threadCount&quot; parameters.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;configuration&amp;gt;
    &amp;lt;parallel&amp;gt;methods&amp;lt;/parallel&amp;gt;
    &amp;lt;perCoreThreadCount&amp;gt;false&amp;lt;/perCoreThreadCounts&amp;gt;
    &amp;lt;threadCount&amp;gt;2&amp;lt;/threadCount&amp;gt;
&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;Considerations&lt;/h2&gt;

&lt;p&gt;Before you dive straight into configuring Maven and JUnit for parallel test execution you need to consider if the test suite is ready for it.  It might not be straight forward to switch test suites straight over without consequences&lt;/p&gt;

&lt;p&gt;The most significant consideration is around your tests being atomic and isolated from each other. This means the results or side effects from previous tests does not affect the execution and result of the current test. A good example of this is stale test data left over from a previous test; the previous test may have deleted or modified data the current depends on. This error may have gone unnoticed due to different test execution ordering in the past.&lt;/p&gt;

&lt;p&gt;One common technique for ensuring test isolation is to setup the System Under Test (SUT) with known clean data before each individual test is executed. People typically do this by using SQL scripts to clean and insert a small amount of data in to the database. With concurrent test execution you will have a problem with this technique due to a race condition in accessing and cleaning the database.  You might be in the middle of executing test 1, and test 2 starts executing and cleaning the database.&lt;/p&gt;

&lt;p&gt;My solution to this problem is to create unique non-repeatable test data on demand (before each test executes). As the data is unique and non-repeatable,  this provides our tests with isolation from each other and avoids having to clean out data from other tests.&lt;/p&gt;

&lt;p&gt;I will be discussing this solution over several blogs in the future, so keep an eye out for them.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>We are attending TestBash 2013</title>
   <link href="http://hindsighttesting.com/blog/2013/03/07/testbash/"/>
   <updated>2013-03-07T00:00:00+00:00</updated>
   <id>http://recursive-design.com/blog/2013/03/07/testbash</id>
   <content type="xhtml">&lt;p&gt;&lt;img style=&quot;float:left; padding-right: 1em; padding-bottom: 1em;&quot; src=&quot;/gallery/testbash.jpg&quot;/&gt;
As active members of the testing community some of the Hindsight team will be attending &lt;a href=&quot;http://www.ministryoftesting.com/training-events/testbash-2-0/&quot;&gt;TestBash 2013&lt;/a&gt; on March 22nd in Brighton, UK. Anyone who wants to chat about Selenium, the testers role in Behaviour Driven Development or Cucumber-JVM should look out for our CEO Alan Parkinson. Just grab him, he won't mind.&lt;/p&gt;

&lt;p&gt;We won't just be at the conference itself, but participating in all the other events going on around it. There is a &lt;a href=&quot;http://www.meetup.com/SoftwareTestingClub/events/98960732/&quot;&gt;Meetup&lt;/a&gt; the night before, a early &lt;a href=&quot;http://www.meetup.com/SoftwareTestingClub/events/107031452/&quot;&gt;morning run&lt;/a&gt; to wake up the brain, &lt;a href=&quot;http://www.meetup.com/SoftwareTestingClub/events/107498512/&quot;&gt;LeanCoffee/LeanTea&lt;/a&gt; before the conference starts and the &lt;a href=&quot;http://www.meetup.com/SoftwareTestingClub/events/98961052/&quot;&gt;social night&lt;/a&gt; after the conference itself. That's one packed schedule with plenty of time for a chat.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Cross browser testing user interface rendering</title>
   <link href="http://hindsighttesting.com/blog/2013/01/21/Cross-browser-testing-user-interface-rendering/"/>
   <updated>2013-01-21T00:00:00+00:00</updated>
   <id>http://recursive-design.com/blog/2013/01/21/Cross-browser-testing-user-interface-rendering</id>
   <content type="xhtml">&lt;p&gt;When it comes to front-end development with Behave for JIRA, I tend to favour Chrome as my web browser of choice but that does not allow me to escape from working with Internet Explorer. At Hindsight, we recognise Behave has to work across any number of browser and OS combinations, with the main challenges lying with Internet Explorer. Luckily IE6 is no longer a problem as Microsoft now considers it obsolete, according to &lt;a href=&quot;http://www.ie6countdown.com/&quot;&gt;IE6 countdown&lt;/a&gt;, its use is down to 0.9% in the UK and 0.4% in the US. That leaves us with Internet Explorer 7 and upwards to consider.&lt;/p&gt;

&lt;h2&gt;Progressive Enhancement v. Graceful Degradation&lt;/h2&gt;

&lt;p&gt;The main issue with Internet Explorer is that each version of Explorer renders Behave's User Interface differently. This is due to Microsoft's inconsistent and idiosyncratic implementation of the rendering engine. In an ideal world one set of standards-based CSS style sheets would be cover all browser options, however this is still some years off. Hindsight's goal is for Behave to support IE 7 (and upwards) but also to provide a rich experience to users of the latest browsers. To ensure compatibility we a choice of 2 techniques - Progressive Enhancement or Graceful Degradation.&lt;/p&gt;

&lt;p&gt;Both techniques work in a layered fashion that allows all users, regardless of Browser variation, to access the basic content and functionality of the Behave for JIRA plugin, while providing the full version of the Behave User Interface to those with more advanced browser software. The practical difference in development techniques is that in Progressive Enhancement I would build from the lowest layer (IE7) upwards, gradually enhancing the User Interface functionality for each individual browser, whereas with Graceful Degradation, I create the full version of the UI first for the modern browsers and then gradually reduce the functionality to suit the needs of those using older browsers.&lt;/p&gt;

&lt;p&gt;Graceful Degradation is the natural choice for me, because I can work locally, in small iterations, on a modern browser. I can play with all the HTML5 features and get feedback as soon as the CSS or JavaScript file in question is saved (thanks to &lt;a href=&quot;http://livereload.com/&quot;&gt;livereload&lt;/a&gt;), leaving browser compatibility until the end of the development cycle. Working &quot;progressively&quot; in the other direction would mean I'd need older (and non-native, given my workstation runs Ubuntu) browsers configured and running on my box from the outset. I would be driven in my development by the limitations of the older browsers, rather than being free to explore the many options new browsers provide.&lt;/p&gt;

&lt;h2&gt;What's the problem?&lt;/h2&gt;

&lt;p&gt;To perform the Graceful Degradation effectively I need access to a wide range of Browser versions and different operating systems. I have to be confident that my 'test' environment is stable enough perform the graceful degradation, as it often requires disabling features and  I only want to do this as a last resort solution.&lt;/p&gt;

&lt;p&gt;Traditionally I would have to set-up a test environment in an isolated virtual machine for each browser and operating system combination. Launching and then maintaining all these environments is a time consuming, hardware intensive and downright inconvenient task - as much as I enjoy a bit of hands on sysadmin work, for me it's a true context shift away from the flow of development.&lt;/p&gt;

&lt;p&gt;What do I want? I want a solution that allows me to...&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Access to a wide range of different browsers and operating systems &quot;mid-flow&quot;&lt;/li&gt;
&lt;li&gt;Do the majority of my development work in Chrome&lt;/li&gt;
&lt;li&gt;Keep all my work local&lt;/li&gt;
&lt;li&gt;Get quick and useful feedback about changes I've made many different browsers&lt;/li&gt;
&lt;li&gt;Know what I see is representative of what a user of that operating system and browser would see&lt;/li&gt;
&lt;li&gt;Reduce the administration and maintenance of test environments&lt;/li&gt;
&lt;/ul&gt;


&lt;h2&gt;What's the Solution?&lt;/h2&gt;

&lt;p&gt;SauceLabs produce a tool called Scout, which provides 96+ different Operating System and Browser combinations. I enter the target URL into Scout, select an operating system and browser, and off I go. As I navigate the website, Scout captures live video, screenshots and makes logs, all of which are available for debrief after I end the test session. I usually keep several tabs open in Scout, one for each of the different browsers I'm testing against, and this  makes corrections simple to implement. But Scout has a limitation - it can only be used to test websites that are publicly exposed. This is a problem because it would require us to host the files on a local web server and expose our network, or to push the files to a remote web server, exposing our code and stopping us from being able to utilize livereload.&lt;/p&gt;

&lt;p&gt;Sauce Connect enables us to use Scout with locally hosted files and bypass the above mentioned issues. Sauce Connect does this by establishing an encrypted SSH tunnel and tunnelling securely between my workstation (in Hindsight  office, behind the Hindsight firewall), and the dedicated, virtual machine in the SauceLabs cloud in California. I simply run a script on my computer to establish this connection, and then I can access my locally running web server through the web browser running in the Sauce Labs cloud. Because Sauce Connect uses an SSH tunnel I don't need to get a system administrator to change any network firewall setting unlike a VPN.&lt;/p&gt;

&lt;p&gt;How does Sauce Connect effect my workflow? No one bit, once I run the script to open the Sauce Connect tunnel, I drop into my normal cycle of amending CSS files locally and refreshing my web browser to view the result, except the web browser in question is in the Sauce Labs cloud!&lt;/p&gt;

&lt;p&gt;You can find out more about Scout and Sauce connect at the &lt;a href=&quot;http://saucelabs.com/home&quot;&gt;SauceLabs Website&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Their free accounts come with 100 Windows, Linux &amp;amp; Android code minutes, 40 Mac &amp;amp; iOS code minutes, plus 30 minutes of manual testing per month. Remember to use the promo code &quot;hindsight&quot; when you sign up for a free or paid plan.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Slides from jDays - Continuous Deployment Pipeline with Maven</title>
   <link href="http://hindsighttesting.com/blog/2012/12/10/jdays-goteborg-continuous-deployment-pipeline-with-maven/"/>
   <updated>2012-12-10T00:00:00+00:00</updated>
   <id>http://recursive-design.com/blog/2012/12/10/jdays-goteborg-continuous-deployment-pipeline-with-maven</id>
   <content type="xhtml">&lt;p&gt;Last week I attended the &lt;a href=&quot;http://www.jdays.se/&quot;&gt;jDays Conference&lt;/a&gt; for Java Professionals and talked about building a &quot;Continuous Deployment Pipeline in Maven&quot;&lt;/p&gt;

&lt;iframe src=&quot;http://www.slideshare.net/slideshow/embed_code/15569541&quot; width=&quot;597&quot; height=&quot;486&quot; frameborder=&quot;0&quot; marginwidth=&quot;0&quot; marginheight=&quot;0&quot; scrolling=&quot;no&quot; style=&quot;border:1px solid #CCC;border-width:1px 1px 0;margin-bottom:5px&quot; allowfullscreen webkitallowfullscreen mozallowfullscreen&gt; &lt;/iframe&gt;


&lt;p&gt;&lt;/p&gt;

&lt;div style=&quot;margin-bottom:5px&quot;&gt; &lt;strong&gt; &lt;a href=&quot;http://www.slideshare.net/alan_parkinson/continuous-deployment-pipeline-with-maven&quot; title=&quot;Continuous Deployment Pipeline with maven&quot; target=&quot;_blank&quot;&gt;Continuous Deployment Pipeline with maven&lt;/a&gt; &lt;/strong&gt; by &lt;strong&gt;&lt;a href=&quot;http://www.slideshare.net/alan_parkinson&quot; target=&quot;_blank&quot;&gt;Alan Parkinson&lt;/a&gt;&lt;/strong&gt; &lt;/div&gt;



</content>
 </entry>
 
 <entry>
   <title>Behave for JIRA Beta discount ending soon</title>
   <link href="http://hindsighttesting.com/blog/2012/11/19/PendingRelease/"/>
   <updated>2012-11-19T00:00:00+00:00</updated>
   <id>http://recursive-design.com/blog/2012/11/19/PendingRelease</id>
   <content type="xhtml">&lt;p&gt;&lt;img style=&quot;float:left; padding-right: 1em; padding-bottom: 1em;&quot; src=&quot;/assets/behave-logo.png&quot;/&gt;&lt;/p&gt;

&lt;p&gt;It's hard to believe its only been 18 weeks since we released the first Beta version of Behave for JIRA.
This period of time has featured some major milestones:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Winning &quot;Best Marketplace paid add-on&quot; in Atlassian's Codegeist competition&lt;/li&gt;
&lt;li&gt;Working with global evaluators including banks, airlines, tv companies, global media companies and international software houses&lt;/li&gt;
&lt;li&gt;Released new features including, support for Ruby, selective test execution and full support for Cucumber.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The great news is that the full release of Behave for JIRA is fast approaching - something we are very excited about.&lt;/p&gt;

&lt;p&gt;However, this means that the 50% discount we have been offering for your massively helpful feedback on our product will be ending very soon.&lt;/p&gt;

&lt;p&gt;&lt;a alt=&quot;Behave at the Atlassian Marketplace&quot; href=&quot;https://marketplace.atlassian.com/plugins/com.hindsighttesting.behave.jira&quot; target=&quot;_blank&quot;&gt;
&lt;img style=&quot;float:right; padding-right: 1em; padding-bottom: 1em;&quot; title=&quot;Behave at the Atlassian Marketplace&quot; alt=&quot;Behave at the Atlassian Marketplace&quot; src=&quot;/assets/marketplace.png&quot;&gt;&lt;/p&gt;

&lt;p style=&quot;font-weight:bold;&quot;&gt;Why not pick up Behave for JIRA now and don't miss out on this 50% discount&lt;/p&gt;


&lt;p&gt;      &lt;br/&gt;
&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Running Automated Tests in Parallel - Part 1</title>
   <link href="http://hindsighttesting.com/blog/2012/10/30/running-tests-in-parallel/"/>
   <updated>2012-10-30T00:00:00+00:00</updated>
   <id>http://recursive-design.com/blog/2012/10/30/running-tests-in-parallel</id>
   <content type="xhtml">&lt;p&gt;Automated functional tests provide valuable feedback to developers by notifying them when they have completed or broken functionality. The value of these tests can be
maximised by providing the test results in the shortest possible time. The reason being the problem is likely to be fresh in the developer's mind and quicker for them to fix.&lt;/p&gt;

&lt;p&gt;A typical functional or UI test suite can take many hours to run because the tests can only be run sequentially. The main cause for the sequential tests is the dependence
on data. Common practice has test cases clear the database of the application under test and populate it with the required data before it starts. This high level of database
manipulation does not allow the tests to be run in parallel because each test will interfere with the database at different times, therefore corrupting data required used by other tests.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/gallery/batched_test_jobs.png&quot; style=&quot;float: right; padding: 1em;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;The common solution for long running test suites is to break them into batches and run each batch on a separate machine with its own instance of the application under test
and its database. This is easy to achieve using spare hardware, Virtual Machine's or Cloud computing resources. You don't even have to write code for spinning up new
machines, or access remote machines, as Continuous Integration (CI) servers like Jenkins and Bamboo provide functionality for running builds on multiple computers. This feature is better known as Slaves or Agents.&lt;/p&gt;

&lt;p&gt;The majority of the popular testing tools have ways of grouping tests together and we can use this feature to create our &quot;Batches&quot; of tests. These features are known as
&quot;categories&quot; in JUnit, &quot;groups&quot; in TestNG and &quot;tags&quot; in Cucumber, Lettuce and Behat.&lt;/p&gt;

&lt;h2&gt;Creating batches of Tests with JUnit&lt;/h2&gt;

&lt;p&gt;JUnit 4.8 introduces a '@Category' annotation for specifying the group that the test class (which will include all the methods within the class) or method belongs to.
The category names for tests are not defined as Strings but as Java Classes, so for each batch or test category we will need to create a Java interface to represent it.
We could create a plain Java Class instead of an interface but as the class will never instantiated and no methods need to be implemented, it's safer to use interfaces.
Tests can be assigned to a category by simply adding the &quot;Category&quot; annotation to the test class or method with the appropriate interface representing the batch as a parameter.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import org.junit.Test;
import org.junit.experimental.categories.Category;
import com.hindsighttesting.junit.batches.BatchA;

@Category(BatchA.class)
public class MyTest {
    @Test
    @Category(Slow.class)
    public void aTest() {
        ...
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;Running a Batch of Tests&lt;/h2&gt;

&lt;p&gt;To adapt an existing Maven build for running your tests using the JUnit categories is rather simple. The first step is to configure the &lt;code&gt;maven-surefire-plugin&lt;/code&gt; to use the correct
JUnit provider. Support for Categories is available in the JUnit 4.7 Surefire Provider and this can be configured just by adding the &lt;code&gt;org.apache.maven.surefire:surefire-junit47&lt;/code&gt;
 dependency to the &lt;code&gt;maven-surefire-plugin&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;build&amp;gt;
    &amp;lt;plugins&amp;gt;
        ...
        &amp;lt;plugin&amp;gt;
            &amp;lt;groupId&amp;gt;org.apache.maven.plugins&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;maven-surefire-plugin&amp;lt;/artifactId&amp;gt;
            &amp;lt;version&amp;gt;2.11&amp;lt;/version&amp;gt;
            &amp;lt;dependencies&amp;gt;
                &amp;lt;dependency&amp;gt;
                    &amp;lt;groupId&amp;gt;org.apache.maven.surefire&amp;lt;/groupId&amp;gt;
                    &amp;lt;artifactId&amp;gt;surefire-junit47&amp;lt;/artifactId&amp;gt;
                    &amp;lt;version&amp;gt;2.12&amp;lt;/version&amp;gt;
                &amp;lt;/dependency&amp;gt;
            &amp;lt;/dependencies&amp;gt;
        &amp;lt;/plugin&amp;gt;
        ...
    &amp;lt;/plugins&amp;gt;
&amp;lt;/build&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;There are two ways of specifying the categories to use for selecting tests to execute. The first is to specify the category in the &lt;code&gt;groups&lt;/code&gt; property of the Plugin configuration within your POM file.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;configuration&amp;gt;
    &amp;lt;groups&amp;gt;com.hindsighttesting.junit.batches.BatchA&amp;lt;/groups&amp;gt;
 &amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The disadvantage of this method is the lack of flexibility in specifying which test batch/category should be executed. You could use Maven profiles to provide the flexibility but this would
increase the size and complexity of the POM file. Handy for us, the &lt;code&gt;groups&lt;/code&gt; property can be specified from the command line as a property.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ mvn test -Dgroups=com.hindsighttesting.junit.batches.BatchA
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;Configuring the Continuous Integration (CI) jobs&lt;/h3&gt;

&lt;p&gt;Now that we know how to select tests as groups to run as batches we need to configure our CI server to schedule and run all our Test batches at the same time. For each batch we need to create
a new build job and configure it to run the appropriate JUnit test batch.&lt;/p&gt;

&lt;p&gt;We need to trigger and execute all our Test batch jobs once the upstream job (&quot;compile&quot; in the diagram) has successfully completed and only execute the downstream job once all the Test batch jobs have completed.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/gallery/ci-job-structure.png&quot; style=&quot;padding: 1em;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;In Jenkins/Hudson we can easily trigger all the test batch jobs by using &lt;code&gt;Post-build Actions&lt;/code&gt; and selecting &lt;code&gt;Build other projects&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/gallery/jenkins-post-build-actions.png&quot; style=&quot;margin-left:auto; margin-right:auto; padding: 1em;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;Waiting for all Batched test jobs to finish before starting the next job is not so simple. For this we require the &lt;a href=&quot;https://wiki.jenkins-ci.org/display/JENKINS/Join+Plugin&quot;&gt;Join Plugin&lt;/a&gt;
and this adds a new &quot;Post-build Action&quot; called &quot;Join Trigger&quot;. The &quot;Join Trigger&quot; is added as a &quot;Post Build action&quot; to the upstream job that triggers our batched test jobs. The upstream job will then trigger the
downstream job to start once all the batched tests are finished.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/gallery/jenkins-join-trigger.png&quot; style=&quot;margin-left:auto; margin-right:auto; padding: 1em;&quot;/&gt;&lt;/p&gt;

&lt;h2&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;We have described a simple way of speeding up large sequential test suites by breaking tests down into batches and running each batch concurrently on separate machines using the slave/agent
functionality of CI servers. It's worth remembering this isn't true concurrent test execution and there are drawbacks to this technique when compared to true concurrency:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Scaling is limited by machine availability&lt;/li&gt;
&lt;li&gt;Available processing power is used inefficiently e.g. by not using all available CPU cores&lt;/li&gt;
&lt;li&gt;Additional time is required to manage batches of tests - tests have to be moved between batches to even out total test execution time.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;At &lt;a href=&quot;http://oredev.org/2012/sessions/cutting-testing-time-with-parallel-automated-functional-tests&quot;&gt;OREDEV 2012&lt;/a&gt; I will be discussing the disadvantages of this pseudo concurrent
technique and how true concurrent test execution can be achieved. For those of you who are not attending OREDEV this year or who miss my presentation (there are so many great presentations scheduled), I will be
following up with additional posts over the next 8 weeks to expand on this topic.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>One day tutorial on Cucumber-JVM at jDays Gothenburg</title>
   <link href="http://hindsighttesting.com/blog/2012/10/08/jDays-GOTEBORG-Cucumber-JVM-Tutorial/"/>
   <updated>2012-10-08T00:00:00+01:00</updated>
   <id>http://recursive-design.com/blog/2012/10/08/jDays-GOTEBORG-Cucumber-JVM-Tutorial</id>
   <content type="xhtml">&lt;p&gt;&lt;img style=&quot;float:left; padding-right: 1em; padding-bottom: 1em;&quot; src=&quot;/gallery/jDays_logo_RGB_speaker_emblem_pa1.png&quot;/&gt; Got the burning desire to learn Cucumber-JVM but don't know where to start? We are pleased to announce that we will be running a one day tutorial on &quot;BDD with Cucumber-JVM&quot; at jDays  Gothenburg on the 5th of December. The tutorial is free for all the attendees of jDays, a three day conference for Java professionals held at the Swedish Exhibition &amp;amp; Congress Centre, Gothenburg
Sweden. Full details are available at the &lt;a href=&quot;http://www.jdays.se/course-information/&quot;&gt;jDays website&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The one day tutorial will give a strong foundation in Cucumber JVM, a rewrite of Cuke4Duke, the tool many Java developers use for writing and running BDD style acceptance tests. The main focus of this course will be on how to write automated acceptance tests for BDD scenarios, though there will be an introduction to BDD given for people not familiar with it.&lt;/p&gt;

&lt;h3&gt;Topics covered:&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;BDD basics&lt;/li&gt;
&lt;li&gt;Automating scenarios by writing Java glue code for Cucumber-JVM&lt;/li&gt;
&lt;li&gt;How to run automated Scenarios using JUnit or Maven&lt;/li&gt;
&lt;li&gt;Grouping scenarios and selecting what gets run with Tags&lt;/li&gt;
&lt;li&gt;Writing common set-up and tear down code for automated scenario's using hooks (@Before and @After)&lt;/li&gt;
&lt;/ul&gt;

</content>
 </entry>
 
 <entry>
   <title>Behave for JIRA wins "Best Marketplace paid add-on" in Codegeist 2012</title>
   <link href="http://hindsighttesting.com/blog/2012/07/30/acceptance-testing-wins-in-codegeist/"/>
   <updated>2012-07-30T00:00:00+01:00</updated>
   <id>http://recursive-design.com/blog/2012/07/30/acceptance-testing-wins-in-codegeist</id>
   <content type="xhtml">&lt;p&gt;&lt;img style=&quot;float:right; padding-left: 1em;&quot; src=&quot;/gallery/codegeist2012_logo.png&quot;/&gt; In a record field of 94 high quality entries Behave for JIRA fought its way to win &quot;Best Marketplace-enabled Plugin&quot; in Atlassian's Codegiest 2012.
Codegiest is annual competition held by Atlassian to find the best product extensions for JIRA, Confluence, GreenHopper, Bamboo, Stash, Bitbucket and the other Atlassian tools.&lt;/p&gt;

&lt;p&gt;This was the 6th running of the annual competition and there were 94 entries, covering 6 different Atlassian products. Judging of the competition of done by Mike Cannon-Brookes (co-CEO of Atlassian), Don Brown and Jonathan Nolen. Contestants had 6 weeks from the announcement of the competition at Atlassian Summit to build their entries.&lt;/p&gt;

&lt;p&gt;Get your full roundup of the Codegiest 2012 results at the &lt;a href=&quot;https://blogs.atlassian.com/2012/07/announcing-the-codegeist-2012-winners/&quot;&gt;Atlassian website&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>A Slice of Pi with your Information Radiator</title>
   <link href="http://hindsighttesting.com/blog/2012/06/01/raspberry-pi-jira-information-raditor/"/>
   <updated>2012-06-01T00:00:00+01:00</updated>
   <id>http://recursive-design.com/blog/2012/06/01/raspberry-pi-jira-information-raditor</id>
   <content type="xhtml">&lt;p&gt;Most of you would of heard of the Raspberry Pi - a low powered credit card sized computer released in the last few months. After a wait I managed to get my hands on one of these nifty devices and have put one of my ideas into action: a power efficient information radiator.&lt;/p&gt;

&lt;p&gt;Information radiators are very useful visual tools that allow anyone at a glance to see the state of the project and receive feedback from important systems. Typically an old or spare PC is used to run a web browser rendering information to a large screen or TV displayed in the team's work area. JIRA has a handy Wallboard plugin that can turn any dashboard into a format to appear on a Information Radiator.&lt;/p&gt;

&lt;p&gt;With PCs using between 60-300 watts of power they are not the most power efficient compared to the Raspberry's 2 watts. The Raspberry Pi also has other benefits.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Cost: Old machines while still capable often need new components due to age and many years of use. The cost of a Raspberry Pi is approx $25-35 per unit depending on the model. This price is often the same or cheaper than replacing a Power supply or Hard disk of a old computer.&lt;/li&gt;
&lt;li&gt;GPIO: The Raspberry has a set of pins which can be used to interface it to electronics. This could be used to drive lamps or LEDs to draw team members attention to the information radiator when important events occur, e.g. Build Fail&lt;/li&gt;
&lt;li&gt;Small and Quiet: The circuit board of the Raspberry could be mounted on the back of the Visual Display whereas a PC is rather large and heavy.&lt;/li&gt;
&lt;/ul&gt;


&lt;h2&gt;Enough of the why, does the Raspberry Pi work?&lt;/h2&gt;

&lt;p&gt;Spoiler alert! It does work but not out of the box.&lt;/p&gt;

&lt;p&gt;My first attempt at the information radiator was using the stock Debian Squeeze distribution provided by the Raspberry Pi Foundation. This distribution comes with the lightweight Webkit (the same engine as Chrome and Safari) based browser, Midori. The version of Midori happens to be 0.2.4-3 and couldn't handle the Javascript with JIRA 5  (I haven't tested other JIRA versions).&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/gallery/RaspberryPiAssembled.jpg&quot;/&gt;&lt;/p&gt;

&lt;h2&gt;Hang on, Firefox and Chrome are both available on Linux.&lt;/h2&gt;

&lt;p&gt;The Raspberry Pi has a ARM 11 based processor so we are limited on choice of Linux distributions and the packages which have been compiled for &quot;armtel&quot;.&lt;/p&gt;

&lt;p&gt;There is a community project &lt;a href=&quot;http://www.raspbian.org/&quot;&gt;raspbian&lt;/a&gt; currently porting the more up to date Debian Whezzy distribution to the ARM processor used in the Raspberry. This saved the day because it provided a cross compiled version of Midori 0.4.3 with good javascript support.&lt;/p&gt;

&lt;p&gt;Raspbian is in the early stages of development and no official images have been provided, but there are Community produce images available. I used the image produced by &lt;a href=&quot;http://www.raspbian.org/HexxehImages&quot;&gt;Hexxeh&lt;/a&gt;, version r3. Once I had written this image to my SD card, I booted the Raspberry Pi and logged in using the &quot;root&quot; user and &quot;hexxeh&quot; password.&lt;/p&gt;

&lt;p&gt;The image is rather simple and we need to add a few extra packages and configurations to make it useful for our purposes.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$ apt-get install ntp fake-hwclock&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$ dpkg-reconfigure tzdata&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$ apt-get install locales&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$ dpkg-reconfigure locales&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$ apt-get install console-data&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$ dpkg-reconfigure console-data&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$ apt-get install lxde-icon-theme&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$ apt-get install midori&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;As JIRA sends a large amount of files and data over HTTP, this can flood the buffers on a swapless system like the Raspberry and lead it to run out of memory. To avoid this a little kernel tweaking needs to take place. Edit &lt;code&gt;/etc/sysctl.conf&lt;/code&gt; (Hint to Linux noobs: &lt;code&gt;nano /etc/sysctl.conf&lt;/code&gt;) and add &lt;code&gt;vm.min_free_kbytes = 8192&lt;/code&gt; as the last line. Reboot the Raspberry (&lt;code&gt;reboot&lt;/code&gt;) and then you are ready to start the GUI with &lt;code&gt;startx&lt;/code&gt; and open the Midori web browser from the Desktop menu and open JIRA with the Wallboard plugin running.&lt;/p&gt;

&lt;h2&gt;Performance&lt;/h2&gt;

&lt;p&gt;My wallboard configuration in JIRA had 2 dashboards setup as a slideshow with slide left animation. My dashboards contained the following Gadgets&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Greenhooper Agile Gadget (Used as a Sprint Burndown graph)&lt;/li&gt;
&lt;li&gt;Greenhooper Rapid Board (Displays our Current sprint task in swimlanes)&lt;/li&gt;
&lt;li&gt;Activity stream&lt;/li&gt;
&lt;li&gt;Several JQL Filter Results&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;There is a initial wait of 30 seconds to load the wallboard slide show and the slide animation between dashboards was a little jerky. But this is be to expected on a low power device without much optimization in the compilation of the web browser and javascript engine. Both these performance issues represent no usability problems as a information radiator due to the fact its not an interactive system. These issue are likely to be reduced with optimisation of the software packages (The current focus is to get them to run) and most importantly improvements in the use of Raspberry's dedicated GPU.&lt;/p&gt;

&lt;h3&gt;Notes&lt;/h3&gt;

&lt;p&gt;I have tested some TV's with the Raspberry PI and the Raspian distribution and some of them have had issues with the xserver. I haven't had enough time to investigate these issues in detail but a manual configuration of the xserver should be the solution.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Security testing with Selenium and the Zed Attack Proxy (ZAP)</title>
   <link href="http://hindsighttesting.com/blog/2012/05/18/automated-security-testing-selenium-zap/"/>
   <updated>2012-05-18T00:00:00+01:00</updated>
   <id>http://recursive-design.com/blog/2012/05/18/automated-security-testing-selenium-zap</id>
   <content type="xhtml">&lt;p&gt;A few weeks ago I had the pleasure of speaking at the 2012 Selenium Conf in London. My presentation was on &quot;Automated Security Testing&quot; using Selenium and the Zed Attack Proxy. All the SeConf presentations have been recorded and I thought I would share my talk with you now it has been published.&lt;/p&gt;

&lt;object style=&quot;height: 460px; width: 760px&quot;&gt;&lt;param name=&quot;wmode&quot; value=&quot;transparent&quot;&gt;&lt;param name=&quot;movie&quot; value=&quot;http://www.youtube.com/v/aVFZFi_6B9g?version=3&amp;feature=player_detailpage&quot;&gt;&lt;param name=&quot;allowFullScreen&quot; value=&quot;true&quot;&gt;&lt;param name=&quot;allowScriptAccess&quot; value=&quot;always&quot;&gt;&lt;embed src=&quot;http://www.youtube.com/v/aVFZFi_6B9g?version=3&amp;feature=player_detailpage&quot; type=&quot;application/x-shockwave-flash&quot; allowfullscreen=&quot;true&quot; allowScriptAccess=&quot;always&quot; width=&quot;760&quot; height=&quot;460&quot;&gt;&lt;/object&gt;


&lt;h3&gt;Recreating my demo&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;Install Chrome if not already installed&lt;/li&gt;
&lt;li&gt;Start Jenkins on port 80. I used a fresh install of Jenkins with no configuration changes&lt;/li&gt;
&lt;li&gt;Start the &lt;a href=&quot;https://www.owasp.org/index.php/OWASP_Zed_Attack_Proxy_Project&quot;&gt;Zed Attack Proxy (ZAP)&lt;/a&gt;, no additional configuration required.&lt;/li&gt;
&lt;li&gt;Run the JUnit test &quot;JobManagementTest&quot; in my &lt;a href=&quot;https://github.com/aparkinson/jenkins-webdriver&quot;&gt;GitHub project&lt;/a&gt;. Note: this test uses Chrome&lt;/li&gt;
&lt;/ol&gt;

</content>
 </entry>
 
 
</feed>


